{
  "cells": [
    {
      "source": [
        "!pip install tensorflow"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNoskmJxF4Z3",
        "outputId": "cc1606e3-c547-40a6-ffc2-78984cdcad6a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7POeWHPYzoXt",
        "outputId": "d36ad0ca-a6cd-42c1-8295-82b3971d8f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "!pip install librosa scikit-learn matplotlib numpy soundfile moviepy pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "jBDn9GSjzqzu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from moviepy.editor import VideoClip, AudioFileClip\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "collapsed": true,
        "id": "bQrl9-b0ztKl"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 22050\n",
        "\n",
        "CHORDS = {\n",
        "    # Major Triads\n",
        "    \"C Major\":   ['C', 'E', 'G'],\n",
        "    \"C# Major\":  ['C#', 'F', 'G#'],\n",
        "    \"D Major\":   ['D', 'F#', 'A'],\n",
        "    \"D# Major\":  ['D#', 'G', 'A#'],\n",
        "    \"E Major\":   ['E', 'G#', 'B'],\n",
        "    \"F Major\":   ['F', 'A', 'C'],\n",
        "    \"F# Major\":  ['F#', 'A#', 'C#'],\n",
        "    \"G Major\":   ['G', 'B', 'D'],\n",
        "    \"G# Major\":  ['G#', 'C', 'D#'],\n",
        "    \"A Major\":   ['A', 'C#', 'E'],\n",
        "    \"A# Major\":  ['A#', 'D', 'F'],\n",
        "    \"B Major\":   ['B', 'D#', 'F#'],\n",
        "\n",
        "    # Minor Triads\n",
        "    \"C Minor\":   ['C', 'D#', 'G'],\n",
        "    \"C# Minor\":  ['C#', 'E', 'G#'],\n",
        "    \"D Minor\":   ['D', 'F', 'A'],\n",
        "    \"D# Minor\":  ['D#', 'F#', 'A#'],\n",
        "    \"E Minor\":   ['E', 'G', 'B'],\n",
        "    \"F Minor\":   ['F', 'G#', 'C'],\n",
        "    \"F# Minor\":  ['F#', 'A', 'C#'],\n",
        "    \"G Minor\":   ['G', 'A#', 'D'],\n",
        "    \"G# Minor\":  ['G#', 'B', 'D#'],\n",
        "    \"A Minor\":   ['A', 'C', 'E'],\n",
        "    \"A# Minor\":  ['A#', 'C#', 'F'],\n",
        "    \"B Minor\":   ['B', 'D', 'F#']\n",
        "}\n",
        "\n",
        "NOTE_FREQ = {\n",
        "    'C': 261.63, 'C#': 277.18, 'D': 293.66, 'D#': 311.13, 'E': 329.63, 'F': 349.23,\n",
        "    'F#': 369.99, 'G': 392.00, 'G#': 415.30, 'A': 440.00, 'A#': 466.16, 'B': 493.88\n",
        "}\n",
        "\n",
        "\n",
        "def synth_chord(notes, duration=1.0, sr=SAMPLE_RATE, noise_level=0.01):\n",
        "    # ... (synth_chord function remains the same) ...\n",
        "    t = np.linspace(0, duration, int(sr * duration), False)\n",
        "    audio = sum(np.sin(2 * np.pi * NOTE_FREQ[note] * t) for note in notes)\n",
        "    audio /= len(notes)\n",
        "\n",
        "    # Apply a simple fade out\n",
        "    fade = np.linspace(1, 0.1, len(audio))\n",
        "    audio = audio * fade\n",
        "\n",
        "    # Add controlled random noise (could be improved with more realistic noise)\n",
        "    noise = noise_level * np.random.randn(len(audio)) * np.random.uniform(0.5, 1.5) # Vary noise level\n",
        "    audio += noise\n",
        "\n",
        "    # Add volume variation\n",
        "    volume_factor = random.uniform(0.8, 1.2)\n",
        "    audio *= volume_factor\n",
        "\n",
        "    # Ensure audio is within valid range\n",
        "    audio = np.clip(audio, -1.0, 1.0)\n",
        "\n",
        "    return audio.astype(np.float32)\n",
        "\n",
        "\n",
        "# Prepare data for CNN\n",
        "X_cnn, y_cnn = [], []\n",
        "max_padding = 0 # To find the maximum feature length for padding\n",
        "\n",
        "for chord_label, notes in CHORDS.items():\n",
        "    for i in range(100):  # Increased samples per chord\n",
        "        duration = random.uniform(0.5, 1.5)\n",
        "        audio = synth_chord(notes, duration=duration)\n",
        "        y_audio = audio\n",
        "\n",
        "        # Extract Mel Spectrogram\n",
        "        # n_mels can be adjusted, n_fft and hop_length affect time/frequency resolution\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y_audio, sr=SAMPLE_RATE, n_mels=128, n_fft=2048, hop_length=512)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "        X_cnn.append(mel_spec_db)\n",
        "        y_cnn.append(chord_label)\n",
        "\n",
        "        # Update max padding\n",
        "        if mel_spec_db.shape[1] > max_padding:\n",
        "            max_padding = mel_spec_db.shape[1]\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "X_padded = []\n",
        "for spec in X_cnn:\n",
        "    padded_spec = librosa.util.pad_center(spec, size=max_padding, axis=1)\n",
        "    X_padded.append(padded_spec)\n",
        "\n",
        "X_padded = np.array(X_padded)\n",
        "# Add channel dimension for CNN input (batch_size, height, width, channels)\n",
        "X_cnn = np.expand_dims(X_padded, axis=-1)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_cnn_encoded = label_encoder.fit_transform(y_cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_cnn_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(X_cnn.shape[1], X_cnn.shape[2], 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5), # Add dropout for regularization\n",
        "    Dense(len(label_encoder.classes_), activation='softmax') # Output layer with number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # Use sparse_categorical_crossentropy for integer labels\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=32, validation_split=0.2) # Use a validation split during training\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# You can also get predictions and use classification_report if needed\n",
        "# y_pred_cnn = model.predict(X_test_cnn)\n",
        "# y_pred_classes = np.argmax(y_pred_cnn, axis=1)\n",
        "# print(\"Test Report with CNN:\\n\", classification_report(y_test_cnn, y_pred_classes, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXnoJog3rUot",
        "outputId": "cec36667-a8d8-4ac4-86e5-abceee024d9c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 486ms/step - accuracy: 0.0390 - loss: 6.2902 - val_accuracy: 0.0417 - val_loss: 3.1727\n",
            "Epoch 2/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 489ms/step - accuracy: 0.0340 - loss: 3.1821 - val_accuracy: 0.0391 - val_loss: 3.1772\n",
            "Epoch 3/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 451ms/step - accuracy: 0.0375 - loss: 3.1777 - val_accuracy: 0.0339 - val_loss: 3.1789\n",
            "Epoch 4/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 475ms/step - accuracy: 0.0461 - loss: 3.1779 - val_accuracy: 0.0469 - val_loss: 3.1773\n",
            "Epoch 5/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 467ms/step - accuracy: 0.1038 - loss: 3.0259 - val_accuracy: 0.7057 - val_loss: 1.1063\n",
            "Epoch 6/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 494ms/step - accuracy: 0.5841 - loss: 1.2134 - val_accuracy: 1.0000 - val_loss: 0.0658\n",
            "Epoch 7/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 476ms/step - accuracy: 0.8875 - loss: 0.3151 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
            "Epoch 8/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 480ms/step - accuracy: 0.9504 - loss: 0.1432 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 9/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 500ms/step - accuracy: 0.9762 - loss: 0.0775 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 10/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 478ms/step - accuracy: 0.9725 - loss: 0.0753 - val_accuracy: 1.0000 - val_loss: 9.5414e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 440ms/step - accuracy: 0.9779 - loss: 0.0542 - val_accuracy: 1.0000 - val_loss: 1.0357e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 473ms/step - accuracy: 0.9831 - loss: 0.0529 - val_accuracy: 1.0000 - val_loss: 1.8534e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 477ms/step - accuracy: 0.9770 - loss: 0.0633 - val_accuracy: 1.0000 - val_loss: 6.7006e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 477ms/step - accuracy: 0.9839 - loss: 0.0602 - val_accuracy: 1.0000 - val_loss: 1.0578e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 450ms/step - accuracy: 0.9887 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 1.2400e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 481ms/step - accuracy: 0.9841 - loss: 0.0435 - val_accuracy: 1.0000 - val_loss: 1.4861e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 450ms/step - accuracy: 0.9833 - loss: 0.0528 - val_accuracy: 1.0000 - val_loss: 1.8878e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 475ms/step - accuracy: 0.9925 - loss: 0.0256 - val_accuracy: 1.0000 - val_loss: 4.9830e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 452ms/step - accuracy: 0.9924 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 3.6657e-06\n",
            "Epoch 20/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 474ms/step - accuracy: 0.9932 - loss: 0.0247 - val_accuracy: 1.0000 - val_loss: 6.3105e-06\n",
            "Epoch 21/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 449ms/step - accuracy: 0.9876 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 6.4462e-06\n",
            "Epoch 22/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 476ms/step - accuracy: 0.9857 - loss: 0.0488 - val_accuracy: 1.0000 - val_loss: 9.9860e-06\n",
            "Epoch 23/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 477ms/step - accuracy: 0.9831 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 2.0121e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 476ms/step - accuracy: 0.9928 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 4.6350e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 527ms/step - accuracy: 0.9945 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 5.2774e-07\n",
            "Epoch 26/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 498ms/step - accuracy: 0.9877 - loss: 0.0253 - val_accuracy: 1.0000 - val_loss: 1.9242e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 470ms/step - accuracy: 0.9955 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 4.9890e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 466ms/step - accuracy: 0.9923 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 4.4392e-07\n",
            "Epoch 29/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 452ms/step - accuracy: 0.9933 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 1.8125e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 433ms/step - accuracy: 0.9903 - loss: 0.0318 - val_accuracy: 1.0000 - val_loss: 4.4518e-06\n",
            "Epoch 31/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 459ms/step - accuracy: 0.9690 - loss: 0.1171 - val_accuracy: 1.0000 - val_loss: 1.8584e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 437ms/step - accuracy: 0.9905 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 2.9183e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 463ms/step - accuracy: 0.9824 - loss: 0.0489 - val_accuracy: 1.0000 - val_loss: 1.0098e-06\n",
            "Epoch 34/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 473ms/step - accuracy: 0.9933 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 4.2313e-07\n",
            "Epoch 35/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 467ms/step - accuracy: 0.9932 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 7.4816e-08\n",
            "Epoch 36/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 448ms/step - accuracy: 0.9899 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 4.3772e-08\n",
            "Epoch 37/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 471ms/step - accuracy: 0.9951 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 1.6546e-07\n",
            "Epoch 38/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 464ms/step - accuracy: 0.9947 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 6.5503e-08\n",
            "Epoch 39/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 464ms/step - accuracy: 0.9919 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 1.1200e-06\n",
            "Epoch 40/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 441ms/step - accuracy: 0.9939 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 1.1673e-07\n",
            "Epoch 41/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 470ms/step - accuracy: 0.9965 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 1.2728e-08\n",
            "Epoch 42/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 440ms/step - accuracy: 0.9993 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 2.2569e-07\n",
            "Epoch 43/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 459ms/step - accuracy: 0.9950 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 2.8543e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 464ms/step - accuracy: 0.9970 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 2.6201e-07\n",
            "Epoch 45/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 479ms/step - accuracy: 0.9927 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 7.4816e-08\n",
            "Epoch 46/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 455ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 8.2577e-08\n",
            "Epoch 47/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 476ms/step - accuracy: 0.9954 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 1.3659e-08\n",
            "Epoch 48/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 465ms/step - accuracy: 0.9939 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 1.2399e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 474ms/step - accuracy: 0.9941 - loss: 0.0251 - val_accuracy: 1.0000 - val_loss: 1.0865e-08\n",
            "Epoch 50/50\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 474ms/step - accuracy: 0.9892 - loss: 0.0298 - val_accuracy: 1.0000 - val_loss: 6.5192e-08\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "3jPSOtxpzzbi"
      },
      "outputs": [],
      "source": [
        "# -- Provide your audio file here:\n",
        "audio_file = \"scientists.wav\"  # <---- CHANGE THIS\n",
        "\n",
        "# Analyze per-beat chords (with ML)\n",
        "y_song, sr = librosa.load(audio_file, sr=SAMPLE_RATE)\n",
        "duration = librosa.get_duration(y=y_song, sr=sr)\n",
        "tempo, beat_frames = librosa.beat.beat_track(y=y_song, sr=sr)\n",
        "beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
        "\n",
        "# Chord prediction per beat using the trained CNN model\n",
        "window_size_samples = int(sr * 1.0)\n",
        "\n",
        "ml_chord_on_beats = []\n",
        "\n",
        "for i, beat_time in enumerate(beat_times):\n",
        "    # Define segment start and end around the beat\n",
        "    start_sample = int(max(0, sr * beat_time - window_size_samples / 2))\n",
        "    end_sample = int(min(len(y_song), sr * beat_time + window_size_samples / 2))\n",
        "    segment = y_song[start_sample:end_sample]\n",
        "\n",
        "    if len(segment) == 0:\n",
        "        ml_chord_on_beats.append((\"Unknown\", beat_time))\n",
        "        continue\n",
        "\n",
        "    # Extract Mel Spectrogram, matching training parameters (n_mels, n_fft, hop_length)\n",
        "    try:\n",
        "        mel_spec = librosa.feature.melspectrogram(y=segment, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "        # Pad the segment's mel spectrogram to the same size as training data\n",
        "        # Use the max_padding value calculated during training data prep\n",
        "        if 'max_padding' not in globals():\n",
        "\n",
        "             pass\n",
        "\n",
        "        # Pad the segment feature\n",
        "        padded_spec = librosa.util.pad_center(mel_spec_db, size=max_padding, axis=1)\n",
        "\n",
        "        # Reshape for CNN input (batch_size=1, height, width, channels=1)\n",
        "        cnn_input_feat = np.expand_dims(np.expand_dims(padded_spec, axis=0), axis=-1)\n",
        "\n",
        "        # Predict using the trained CNN model\n",
        "        prediction_proba = model.predict(cnn_input_feat, verbose=0)\n",
        "        predicted_class_index = np.argmax(prediction_proba, axis=1)[0]\n",
        "        # Decode the numerical prediction back to chord label\n",
        "        chord_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle potential errors during feature extraction or prediction\n",
        "        print(f\"Error processing segment at beat time {beat_time}: {e}\")\n",
        "        chord_label = \"Unknown\"\n",
        "\n",
        "\n",
        "    ml_chord_on_beats.append((chord_label, beat_time))\n",
        "\n",
        "# Merge repeated chords for better visuals\n",
        "chord_timeline = []\n",
        "# Include the end of the song for the last beat's chord duration\n",
        "beat_times_with_end = np.append(beat_times, duration)\n",
        "\n",
        "for i in range(len(beat_times_with_end) - 1):\n",
        "    # Ensure ml_chord_on_beats has an entry for each beat time\n",
        "    # If a beat segment was empty, it would have been added as \"Unknown\"\n",
        "    if i < len(ml_chord_on_beats):\n",
        "        chord_label = ml_chord_on_beats[i][0]\n",
        "        start_time = beat_times_with_end[i]\n",
        "        end_time = beat_times_with_end[i+1]\n",
        "        chord_timeline.append((start_time, end_time, chord_label))\n",
        "    else:\n",
        "        # Handle cases where ml_chord_on_beats might be shorter than beat_times\n",
        "        print(f\"Warning: No chord prediction for beat index {i}\")\n",
        "        last_known_chord = ml_chord_on_beats[-1][0] if ml_chord_on_beats else \"Unknown\"\n",
        "        start_time = beat_times_with_end[i]\n",
        "        end_time = beat_times_with_end[i+1]\n",
        "        chord_timeline.append((start_time, end_time, last_known_chord))\n",
        "\n",
        "\n",
        "merged_chords = []\n",
        "for segment in chord_timeline:\n",
        "    if not merged_chords or merged_chords[-1][2] != segment[2]:\n",
        "        merged_chords.append(segment)\n",
        "    else:\n",
        "        merged_chords[-1] = (merged_chords[-1][0], segment[1], merged_chords[-1][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "9xtME5rz0qv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ad17ea-d0c9-4343-fe9b-2e24c3da308d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /tmp/tmp450u2gsi.mp4.\n",
            "MoviePy - Writing audio in tmp450u2gsiTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /tmp/tmp450u2gsi.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /tmp/tmp450u2gsi.mp4\n"
          ]
        }
      ],
      "source": [
        "chord_palette = {\n",
        "    # Major chords – cheerful, warm, and vivid\n",
        "    \"C Major\":   ((255, 255, 0),     'circle'),     # Bright Yellow – Happy, sunny resolution\n",
        "    \"C# Major\":  ((255, 0, 255),     'triangle'),   # Magenta – vivid, expressive\n",
        "    \"D Major\":   ((0, 255, 0),       'circle'),     # Vibrant Green – Triumphant, fresh\n",
        "    \"D# Major\":  ((255, 153, 51),    'hex'),        # Warm Orange – bold, animated\n",
        "    \"E Major\":   ((255, 51, 255),    'star'),       # Light Magenta – open and colorful\n",
        "    \"F Major\":   ((255, 204, 0),     'rect'),       # Golden Yellow – bright, balanced\n",
        "    \"F# Major\":  ((102, 255, 102),   'triangle'),   # Soft Mint – smooth and lush\n",
        "    \"G Major\":   ((255, 85, 0),      'circle'),     # Orange-Red – lively, warm\n",
        "    \"G# Major\":  ((255, 0, 102),     'star'),       # Hot Pink – playful, vivid\n",
        "    \"A Major\":   ((255, 255, 255),   'rect'),       # White – radiant, uplifting (you may change this)\n",
        "    \"A# Major\":  ((0, 255, 255),     'triangle'),   # Cyan – energetic and clear\n",
        "    \"B Major\":   ((255, 0, 0),       'hex'),        # True Red – confident, intense\n",
        "\n",
        "    # Minor chords – deep, melancholic, or rich\n",
        "    \"C Minor\":   ((51, 0, 153),      'rect'),       # Indigo – calm, reflective\n",
        "    \"C# Minor\":  ((75, 0, 130),      'hex'),        # Dark Violet – poetic, obscure\n",
        "    \"D Minor\":   ((0, 102, 204),     'triangle'),   # Deep Blue – introspective\n",
        "    \"D# Minor\":  ((102, 0, 204),     'star'),       # Midnight Purple – mysterious\n",
        "    \"E Minor\":   ((153, 51, 255),    'triangle'),   # Rich Violet – somber but rich\n",
        "    \"F Minor\":   ((0, 51, 153),      'hex'),        # Navy Blue – deep, serious\n",
        "    \"F# Minor\":  ((0, 0, 204),       'star'),       # Cobalt – cold, immersive\n",
        "    \"G Minor\":   ((30, 70, 180),     'rect'),       # Ocean Blue – fragile, thoughtful\n",
        "    \"G# Minor\":  ((60, 60, 220),     'triangle'),   # Steel Blue – icy, controlled\n",
        "    \"A Minor\":   ((0, 0, 153),       'triangle'),   # Deep Blue – sad or mellow\n",
        "    \"A# Minor\":  ((102, 0, 204),     'star'),       # Blue-Violet – dramatic, mysterious\n",
        "    \"B Minor\":   ((85, 85, 255),     'hex'),        # Electric Indigo – nostalgic, dreamy\n",
        "\n",
        "    \"Unknown\":   ((160, 160, 160),   'circle')      # Mid Gray – undefined\n",
        "}\n",
        "W, H = 720, 720\n",
        "\n",
        "\n",
        "def draw_shape(draw, shape, color, size, center, t_frac):\n",
        "    x, y = center\n",
        "    if shape == \"circle\":\n",
        "        r = int(size * (0.9 + 0.15*np.sin(2*np.pi*t_frac)))\n",
        "        draw.ellipse([x - r, y - r, x + r, y + r], fill=color, outline=None)\n",
        "    elif shape == \"rect\":\n",
        "        s = int(size * (0.85 + 0.2*np.cos(2*np.pi*t_frac)))\n",
        "        draw.rectangle([x - s, y - s, x + s, y + s], fill=color)\n",
        "    elif shape == \"triangle\":\n",
        "        s = int(size * (0.85 + 0.2*np.sin(4*np.pi*t_frac)))\n",
        "        pts = [(x, y - s), (x - s, y + s), (x + s, y + s)]\n",
        "        draw.polygon(pts, fill=color)\n",
        "    elif shape == \"hex\":\n",
        "        s = int(size * (0.85 + 0.15*np.cos(4*np.pi*t_frac)))\n",
        "        angle = np.linspace(0, 2*np.pi, 7)\n",
        "        pts = [(x + s*np.cos(a), y + s*np.sin(a)) for a in angle]\n",
        "        draw.polygon(pts, fill=color)\n",
        "    elif shape == \"star\":\n",
        "        s = size\n",
        "        pts = []\n",
        "        for i in range(10):\n",
        "            r = s if i % 2 == 0 else s//2\n",
        "            theta = np.pi/5 * i + 2*np.pi*t_frac\n",
        "            pts.append((x + int(r * np.sin(theta)), y - int(r * np.cos(theta))))\n",
        "        draw.polygon(pts, fill=color)\n",
        "    # More shapes\n",
        "\n",
        "def make_frame(t):\n",
        "    idx = np.searchsorted([bt for _, bt in ml_chord_on_beats], t, side='right') - 1\n",
        "    chord, bt = ml_chord_on_beats[max(idx, 0)]\n",
        "    color, shape = chord_palette.get(chord, ((180,180,180), \"circle\"))\n",
        "    img = Image.new(\"RGB\", (W, H), (30, 30, 30))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # Artistic transitions\n",
        "    next_idx = min(idx+1, len(ml_chord_on_beats)-1)\n",
        "    bt1 = ml_chord_on_beats[idx][1]\n",
        "    bt2 = ml_chord_on_beats[next_idx][1] if next_idx != idx else duration\n",
        "    t_frac = (t - bt1) / max(0.001, (bt2 - bt1))\n",
        "    next_color = chord_palette.get(ml_chord_on_beats[next_idx][0], ((180,180,180), shape))[0]\n",
        "    curr_col = tuple(int((1-t_frac)*c1 + t_frac*c2) for c1, c2 in zip(color, next_color))\n",
        "    draw_shape(draw, shape, curr_col, 170, (W//2, H//2), t_frac)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 54)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "    draw.text((W//2-70, H//2+180), chord, font=font, fill=(255,255,255,220))\n",
        "    return np.array(img)\n",
        "\n",
        "# %%\n",
        "video_duration = duration\n",
        "video = VideoClip(make_frame, duration=video_duration)\n",
        "audio = AudioFileClip(audio_file).subclip(0, video_duration)\n",
        "video = video.set_audio(audio)\n",
        "\n",
        "outpath = tempfile.mktemp(suffix='.mp4')\n",
        "video.write_videofile(outpath, fps=12, codec=\"libx264\", audio_codec=\"aac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "iWdAhkMB0u0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a13eeb5-5de7-4ac6-d0d2-61466d7d7900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /tmp/tmpn1g8wwom.mp4.\n",
            "MoviePy - Writing audio in tmpn1g8wwomTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /tmp/tmpn1g8wwom.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /tmp/tmpn1g8wwom.mp4\n"
          ]
        }
      ],
      "source": [
        "video_duration = duration\n",
        "video = VideoClip(make_frame, duration=video_duration)\n",
        "audio = AudioFileClip(audio_file).subclip(0, video_duration)\n",
        "video = video.set_audio(audio)\n",
        "\n",
        "outpath = tempfile.mktemp(suffix='.mp4')\n",
        "video.write_videofile(outpath, fps=12, codec=\"libx264\", audio_codec=\"aac\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}